{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nltk_tweets.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMI4fkLGF/rDRMtHjD7R9eZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saulomaia/datascience/blob/master/nlp_nltk/nltk_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pEet29rciom",
        "colab_type": "text"
      },
      "source": [
        "# **NLTK - Base de Dados em Português**\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/saulomaia/datascience/master/images/image_post.png\" height=\"450px\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-wuv_muc7ia",
        "colab_type": "text"
      },
      "source": [
        "## **Aplicando NLTK em uma base de dados em português com dados do Twitter**\n",
        "\n",
        "Este projeto, envolve processamento de linguagem natural (*natural language processing - NLP*) e a ferramenta ***NLTK***.\n",
        "\n",
        "### **Mineração de Textos**\n",
        "\n",
        "Mineração de textos é uma técnica usada para tirar valiosas informações de bases de dados de textos.\n",
        "\n",
        "Também chamamos de *Natural Language Processing* que significa **Processamento de Lingugagem Natural** ou NLP.\n",
        "\n",
        "A grande crescente dessa área é devido a enorme quantidade de dados que temos hoje. Atualmente existe um grande número de dados sendo gerados a todo minuto, e muito desses tipos de dados, são dados de texto. E existem tarefas que podem resolver problemas importantes ou podem gerar bastante valor.\n",
        "\n",
        "**Por que aprender mineração de textos ?**\n",
        "\n",
        "*   Automatização da comunicação entre pessoas ou serviços\n",
        "*   Extração de conhecimento em base de dados de texto\n",
        "\n",
        "\n",
        "Dentre os recursos disponíveis para se trabalhar com mineração de textos temos algumas funções nativas do Python, temos a biblioteca NLTK, bibliotecas para NLP, dicionários léxicos, *machine learning* e até mesmo *deep learning*.\n",
        "\n",
        "**Algumas ferramentas:**\n",
        "\n",
        "\n",
        "1.   **Wordnet**\n",
        "\n",
        "      Famoso dicionário léxico de substantivos, verbos, adjetivos, advérbios que são agrupados por conceitos. Essa ferramenta está disponível gratuitamente.\n",
        "\n",
        "2.   ***Part os Speech***\n",
        "\n",
        "      Técnica que consiste em classificar uma palavra por sua função gramatical.Técnica muito utilizada no processamento de textos, mas a função gramatical de uma certa palavra altera conforme o emprego da mesma na frase, e principalmente no idioma português, essa é uma técnica complexa.\n",
        "\n",
        "3.   **Reconhecimento de Entidades** \n",
        "\n",
        "      A partir de dados no texto, um modelo é utilizado para reconhecimento de padrões definidos pelo usuário.  Esta técnica pode utilizar *machine learning* ou não. Para o reconhecimento de entidades, a técnica *part os speech* pode ter uma função especial.\n",
        "\n",
        "4.   **Análise de Sentimentos** \n",
        "\n",
        "      A tarefa de análise de sentimentos é uma tarefa muito demandada quando se trabalha com textos. Pode se utilizar diversos métodos como léxicos ou *machine learning*. E essa tarefa também pode ser base para outras aplicações. Exemplo: *reviews* de filmes, de produtos, marcas, serviços, reputação de pessoas públicas...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uEP5DiOeNyh",
        "colab_type": "text"
      },
      "source": [
        "###**Projeto - Parte 1**\n",
        "\n",
        "O objetivo desse projeto é mostrar como fazer algumas análises e explorar uma base de dados em português utilizando NLTK, visto que trabalhar com as técnicas de NLP atuais em textos e português tem se mostrado um grande desafio.\n",
        "\n",
        "Neste projeto utilizaremos uma **base de dados de tweets** reais relacionados ao governo de **Minas Gerais**. A base de dados é composta por **8199 linhas** classificadas como positivo, negativo e neutro.\n",
        "\n",
        "O Twitter é um serviço muito utilizado por empresas para análises, principalmente análise de sentimentos. A análise de sentimentos é uma técnica que tem o objetivo de extrair informações de textos em linguagem natural. Deseja-se então obter, de forma automática, a polaridade de um texto ou sentença. Por exemplo, dado um texto, o computador classificar como positivo ou negativo tal conteúdo.\n",
        "\n",
        "Trabalhar com o idioma português ainda é um desafio quando se deseja aplicar processamento de linguagem natural, então a escolha dessa base de dados nos dará condições de explorar e fazer algumas análises usando NLTK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuukGfxWgfwj",
        "colab_type": "text"
      },
      "source": [
        "###**Importando a base de dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVFG6FFEg4fv",
        "colab_type": "text"
      },
      "source": [
        "Como vamos tratar com dados reais que foram coletados de forma automatizada, nossa base de dados se assemelha muito de bases comumente usadas em projetos de *data science*. Ou seja, bastante \"suja\", com caracteres faltantes e/ou dados coletados errôneamente.\n",
        "\n",
        "####**OBS: a coluna \"Text\" é o tweet propriamente dito.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFvFVs7HgkHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "500cbf01-80c9-4c5e-aa05-1dbd56df7d72"
      },
      "source": [
        "# Setup\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p0NChEcgr7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_csv('Tweets_Mg.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkTK-bY6gthy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "33381733-9168-4de6-c51b-06621cfe353d"
      },
      "source": [
        "tweets.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Created At</th>\n",
              "      <th>Text</th>\n",
              "      <th>Geo Coordinates.latitude</th>\n",
              "      <th>Geo Coordinates.longitude</th>\n",
              "      <th>User Location</th>\n",
              "      <th>Username</th>\n",
              "      <th>User Screen Name</th>\n",
              "      <th>Retweet Count</th>\n",
              "      <th>Classificacao</th>\n",
              "      <th>Observação</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "      <th>Unnamed: 17</th>\n",
              "      <th>Unnamed: 18</th>\n",
              "      <th>Unnamed: 19</th>\n",
              "      <th>Unnamed: 20</th>\n",
              "      <th>Unnamed: 21</th>\n",
              "      <th>Unnamed: 22</th>\n",
              "      <th>Unnamed: 23</th>\n",
              "      <th>Unnamed: 24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
              "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brasil</td>\n",
              "      <td>Leonardo C Schneider</td>\n",
              "      <td>LeoCSchneider</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
              "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
              "      <td>-41.9333</td>\n",
              "      <td>-18.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wândell</td>\n",
              "      <td>klefnews</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
              "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
              "      <td>-41.9333</td>\n",
              "      <td>-18.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wândell</td>\n",
              "      <td>klefnews</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Wed Jan 04 21:43:51 +0000 2017</td>\n",
              "      <td>��� https://t.co/BnDsO34qK0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ana estudando</td>\n",
              "      <td>estudandoconcur</td>\n",
              "      <td>0</td>\n",
              "      <td>Neutro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
              "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Emily</td>\n",
              "      <td>Milly777</td>\n",
              "      <td>0</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                      Created At  ... Unnamed: 23  Unnamed: 24\n",
              "0           0  Sun Jan 08 01:22:05 +0000 2017  ...         NaN          NaN\n",
              "1           1  Sun Jan 08 01:49:01 +0000 2017  ...         NaN          NaN\n",
              "2           2  Sun Jan 08 01:01:46 +0000 2017  ...         NaN          NaN\n",
              "3           3  Wed Jan 04 21:43:51 +0000 2017  ...         NaN          NaN\n",
              "4           4  Mon Jan 09 15:08:21 +0000 2017  ...         NaN          NaN\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZZlSOTNh3Vr",
        "colab_type": "text"
      },
      "source": [
        "Exibindo, por exemplo, as **10 primeiras linhas da coluna \"Text\"**, podemos ver que há *tweets* relacionados à **segurança, educação, infraestrutura do Estado**, ou seja, uma série de termos que que foram usadados na coleta e que serão analisados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAWFAFXgwDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "b056e7ff-4e11-4bb3-ffc7-57bf79898cec"
      },
      "source": [
        "tweets.Text.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    ���⛪ @ Catedral de Santo Antônio - Governador ...\n",
              "1    � @ Governador Valadares, Minas Gerais https:/...\n",
              "2    �� @ Governador Valadares, Minas Gerais https:...\n",
              "3                          ��� https://t.co/BnDsO34qK0\n",
              "4    ��� PSOL vai questionar aumento de vereadores ...\n",
              "5    \" bom é bandido morto\"\\nDeputado Cabo Júlio é ...\n",
              "6    \"..E 25% dos mineiros dizem não torcer para ti...\n",
              "7    \"A gigantesca barba do mal\" em destaque no cad...\n",
              "8    \"BB e governo de Minas travam disputa sobre de...\n",
              "9    \"com vcs bh fica pequena!\" Belo Horizonte (pro...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6LjXa1Dik3W",
        "colab_type": "text"
      },
      "source": [
        "Utilizando o **método \"count()\"**, conseguimos ter uma noção da dimensão da nossa base de dados, ou seja, vemos que a mesma é composta por **8199 *tweets* relacionados ao governo de MG.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgHjGteJhf0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "665c4a04-2642-453f-ad4f-f8dcb5cfa380"
      },
      "source": [
        "tweets.count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                   8199\n",
              "Created At                   8199\n",
              "Text                         8199\n",
              "Geo Coordinates.latitude      104\n",
              "Geo Coordinates.longitude     104\n",
              "User Location                5489\n",
              "Username                     8199\n",
              "User Screen Name             8199\n",
              "Retweet Count                8199\n",
              "Classificacao                8199\n",
              "Observação                      1\n",
              "Unnamed: 10                     0\n",
              "Unnamed: 11                     0\n",
              "Unnamed: 12                     0\n",
              "Unnamed: 13                     0\n",
              "Unnamed: 14                     0\n",
              "Unnamed: 15                     0\n",
              "Unnamed: 16                     0\n",
              "Unnamed: 17                     0\n",
              "Unnamed: 18                     0\n",
              "Unnamed: 19                     0\n",
              "Unnamed: 20                     0\n",
              "Unnamed: 21                     0\n",
              "Unnamed: 22                     0\n",
              "Unnamed: 23                     0\n",
              "Unnamed: 24                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMKHpFoxikOn",
        "colab_type": "text"
      },
      "source": [
        "###**Tokenization dos tweets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPXzDWMgi6bL",
        "colab_type": "text"
      },
      "source": [
        "*Tokenização* é a capacidade de **reconhecer palavras e sentenças** em uma frase ou texto. Ou seja, no contexto de uma frase, a tokenização é reconhecer cada palavra daquela frase. Aplicando-a em um texto, por exemplo, o processo se dá em reconhecer sentenças (frases, quebras de linhas...).\n",
        "\n",
        "Existem **diversos tipos de tokenizadores**, porém para cada idioma, para cada contexto do problema o qual você está trabalhando, há um certo desafio/peculiaridades ao se aplicar o processo de *tokenização*.\n",
        "\n",
        "A própria NLTK possue alguns *tokenizadores* que deve ser usado **dependendo de qual domínio você esteja trabalhando**. Como estamos trabalhando com dados do Twiter, usaremos o \"**TweetTokenizer**\", mas mostrarei a diferença desse tipo de *tokenizador*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddMaiLaGlA-1",
        "colab_type": "text"
      },
      "source": [
        "Mostrando, primeramente, o resultado do tokenizador \"**word_tokenize**\" que é um dos mais simples e comum para identificação de palavras em uma frase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRmd_05uihc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "6d882422-df9f-43dc-8dbb-807cc82b3da4"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"RT @saulo10 I like very Loooooot this movieee!!, thanks ;) :) :-)\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@',\n",
              " 'saulo10',\n",
              " 'I',\n",
              " 'like',\n",
              " 'very',\n",
              " 'Loooooot',\n",
              " 'this',\n",
              " 'movieee',\n",
              " '!',\n",
              " '!',\n",
              " ',',\n",
              " 'thanks',\n",
              " ';',\n",
              " ')',\n",
              " ':',\n",
              " ')',\n",
              " ':',\n",
              " '-',\n",
              " ')']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NGKQCsZlsIp",
        "colab_type": "text"
      },
      "source": [
        "A aplicação do \"**word_tokenizer**\" resulta no reconhecimento de várias instâncias nessa frase de exemplo.\n",
        "\n",
        "Mas talvez para uma base de dados do Twiter, não faça tanto sentido reconhecer o caractere **\":\"**(dois pontos) individualmente. Nós sabemos que o usuário quis usar o conjunto **:)** (emoji de carinha sorrindo), assim como os outros emojis, sendo assim uma limitação do tokenizador para esse tipo de dado.\n",
        "\n",
        "Aplicando então o \"**TweetTokenizer**\"..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TZnhlfklekw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d3f37a2a-6405-4782-a441-daa00041f70b"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "tweet_tokenize = TweetTokenizer()\n",
        "tweet_tokenize.tokenize(\"RT @saulo10 I like very Loooooot this movieee!!, thanks ;) :) :-)\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT',\n",
              " '@saulo10',\n",
              " 'I',\n",
              " 'like',\n",
              " 'very',\n",
              " 'Loooooot',\n",
              " 'this',\n",
              " 'movieee',\n",
              " '!',\n",
              " '!',\n",
              " ',',\n",
              " 'thanks',\n",
              " ';)',\n",
              " ':)',\n",
              " ':-)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fcxcMK0mh6T",
        "colab_type": "text"
      },
      "source": [
        "Vemos então, que utilizando um tokenizador próprio para uma base de dados do Twiter, treinado com esse tipo de dados, os emojis, por exemplo, são reconhecidos como uma instância única, como um token único.\n",
        "\n",
        "Isso mostra a **capacidade de tokenizador em identificar esse tipo de caracteres** e figuras de linguagens que são típicos e muito utlizados no Twiter.\n",
        "\n",
        "Vale ressaltar então, que **a escolha do tokenizador é um ponto importante** que pode fazer muita diferença nas análises seguintes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR8sFcoqp7vS",
        "colab_type": "text"
      },
      "source": [
        "###Visualizando o resultado do TweetTokenizer\n",
        "\n",
        "*   **Tweet**: Texto original escrito pelo usuário\n",
        "*   **Token**: Resultado do processo de tokenização ao aplicar o TweetTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI_kND_Cmewb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "30de47ab-f1ab-470f-8abb-8b3bda9ff7a0"
      },
      "source": [
        "tweet_tokenize = TweetTokenizer()\n",
        "for t in tweets.Text.head(10).items():\n",
        "    print (\"Tweet:\", t[1])\n",
        "    print (\"Tokens:\", tweet_tokenize.tokenize(t[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet: ���⛪ @ Catedral de Santo Antônio - Governador Valadares/MG https://t.co/JSbKamIqUJ\n",
            "Tokens: ['�', '�', '�', '⛪', '@', 'Catedral', 'de', 'Santo', 'Antônio', '-', 'Governador', 'Valadares', '/', 'MG', 'https://t.co/JSbKamIqUJ']\n",
            "Tweet: � @ Governador Valadares, Minas Gerais https://t.co/B3ThIDJCSf\n",
            "Tokens: ['�', '@', 'Governador', 'Valadares', ',', 'Minas', 'Gerais', 'https://t.co/B3ThIDJCSf']\n",
            "Tweet: �� @ Governador Valadares, Minas Gerais https://t.co/dPkgzVR2Qw\n",
            "Tokens: ['�', '�', '@', 'Governador', 'Valadares', ',', 'Minas', 'Gerais', 'https://t.co/dPkgzVR2Qw']\n",
            "Tweet: ��� https://t.co/BnDsO34qK0\n",
            "Tokens: ['�', '�', '�', 'https://t.co/BnDsO34qK0']\n",
            "Tweet: ��� PSOL vai questionar aumento de vereadores e prefeito de BH na Justiça - Politica - Estado de Minas https://t.co/DMg7BGsek5\n",
            "Tokens: ['�', '�', '�', 'PSOL', 'vai', 'questionar', 'aumento', 'de', 'vereadores', 'e', 'prefeito', 'de', 'BH', 'na', 'Justiça', '-', 'Politica', '-', 'Estado', 'de', 'Minas', 'https://t.co/DMg7BGsek5']\n",
            "Tweet: \" bom é bandido morto\"\n",
            "Deputado Cabo Júlio é condenado e fica inelegível por 10 anos - Politica - Estado de Minas https://t.co/3GfAqvrFHS\n",
            "Tokens: ['\"', 'bom', 'é', 'bandido', 'morto', '\"', 'Deputado', 'Cabo', 'Júlio', 'é', 'condenado', 'e', 'fica', 'inelegível', 'por', '10', 'anos', '-', 'Politica', '-', 'Estado', 'de', 'Minas', 'https://t.co/3GfAqvrFHS']\n",
            "Tweet: \"..E 25% dos mineiros dizem não torcer para time nenhum,mesmo dentro de um estado com Atlético-MG e Cruzeiro. Pq?..\" https://t.co/fN5evlLQsR\n",
            "Tokens: ['\"', '..', 'E', '25', '%', 'dos', 'mineiros', 'dizem', 'não', 'torcer', 'para', 'time', 'nenhum', ',', 'mesmo', 'dentro', 'de', 'um', 'estado', 'com', 'Atlético-MG', 'e', 'Cruzeiro', '.', 'Pq', '?', '..', '\"', 'https://t.co/fN5evlLQsR']\n",
            "Tweet: \"A gigantesca barba do mal\" em destaque no caderno Cultura do Estado de Minas. https://t.co/PxNurIkTlw\n",
            "Tokens: ['\"', 'A', 'gigantesca', 'barba', 'do', 'mal', '\"', 'em', 'destaque', 'no', 'caderno', 'Cultura', 'do', 'Estado', 'de', 'Minas', '.', 'https://t.co/PxNurIkTlw']\n",
            "Tweet: \"BB e governo de Minas travam disputa sobre depósitos judiciais\" https://t.co/CnMu2A2Qo5\n",
            "Tokens: ['\"', 'BB', 'e', 'governo', 'de', 'Minas', 'travam', 'disputa', 'sobre', 'depósitos', 'judiciais', '\"', 'https://t.co/CnMu2A2Qo5']\n",
            "Tweet: \"com vcs bh fica pequena!\" Belo Horizonte (pron. [bɛloɾiˈzõntʃi][10]) é a capital do estado de MG, com uma área de aproximadamente 331 km²\n",
            "Tokens: ['\"', 'com', 'vcs', 'bh', 'fica', 'pequena', '!', '\"', 'Belo', 'Horizonte', '(', 'pron', '.', '[', 'bɛloɾiˈzõntʃi', ']', '[', '10', ']', ')', 'é', 'a', 'capital', 'do', 'estado', 'de', 'MG', ',', 'com', 'uma', 'área', 'de', 'aproximadamente', '331', 'km²']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX7l8B3frDqV",
        "colab_type": "text"
      },
      "source": [
        "Já antecipando processamentos futuros a serem realizados com a NLTK, precisamos gerar uma lista de palavras a partir dos tokens ou termos da nossa base de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7KPSwB2qNtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "10ef0321-1c30-4264-eda4-349b061876e9"
      },
      "source": [
        "from functools import reduce\n",
        "import operator\n",
        "\n",
        "list_palavras = []\n",
        "\n",
        "for t in tweets.Text.items():\n",
        "    list_palavras.append(t[1].split())\n",
        "\n",
        "# Reduz a lista de listas em apenas uma lista única de elementos.\n",
        "list_palavras = reduce(operator.concat, list_palavras)\n",
        "list_palavras[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['���⛪',\n",
              " '@',\n",
              " 'Catedral',\n",
              " 'de',\n",
              " 'Santo',\n",
              " 'Antônio',\n",
              " '-',\n",
              " 'Governador',\n",
              " 'Valadares/MG',\n",
              " 'https://t.co/JSbKamIqUJ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yJrngbJrQlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d6f24e8-2b27-41fb-fe1c-6acade9974b5"
      },
      "source": [
        "len(list_palavras)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDsXvu_3rvSs",
        "colab_type": "text"
      },
      "source": [
        "###**Gerando um objeto do tipo *nltk*.Text a partir da lista de palavras**\n",
        "\n",
        "Esse método me permite agora trabalhar com vários outros métodos como colocações, concordância, visualização e até vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrnwVPLrT0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets_text_nltk = nltk.Text(list_palavras)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvSGQ0aqszfT",
        "colab_type": "text"
      },
      "source": [
        "###**Encontrando a frequência do token \"Minas\" e \"Pimentel\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTo-npAnsIuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14eca099-8f91-450b-b878-4864851029fd"
      },
      "source": [
        "tweets_text_nltk.count(\"Minas\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHbqbQUys4-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc1f3c59-6628-46cf-fcab-5b9ca6c8001e"
      },
      "source": [
        "tweets_text_nltk.count(\"Pimentel\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "418"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf0m8MT7tMA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNÇÃO PARA CÁLCULO DO PERCENTUAL REPRESENTADO POR UMA PALAVRA SOBRE A BASE DE DADOS\n",
        "\n",
        "def palavra_percentual(freq, dataset):\n",
        "    total = len(dataset)\n",
        "    return 100 * freq / total"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvDJqTyctmPH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d23a5c0-8b1d-46de-b582-236531616329"
      },
      "source": [
        "palavra_percentual(list_palavras.count('Minas'), list_palavras)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9842679139495696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq910Hf_toZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a71da75-f6c4-48a0-afb2-8af8ddf7c1e2"
      },
      "source": [
        "palavra_percentual(list_palavras.count('Pimentel'), list_palavras)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3158507189759787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qeAsiDNuX7M",
        "colab_type": "text"
      },
      "source": [
        "###**Similaridade de palavras por contexto**\n",
        "\n",
        "O método \".similar()\" me permite buscar na base de dados, palavras similares a uma outra determinada palavra e/ou que aparecem no mesmo contexto, e exibe, por padrão, as 20 primeiras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWsV682stqHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "aeabcaf3-8e9c-47bd-8f26-38f734df1d0c"
      },
      "source": [
        "tweets_text_nltk.similar(\"Minas\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mg rt drogas roubo estado o fora bh pimentel anos que governo sp\n",
            "manaus um calamidade casos segurança temer presídio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX9lW26JvIu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c141036a-2e20-41d4-d25d-6ed7ba8d509c"
      },
      "source": [
        "tweets_text_nltk.similar(\"Gerais\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rt que politica e para economia governador é não do no mantém melhor\n",
            "deste de com governo tem q o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFJ2gX6juouh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6aad49b6-b32c-4818-971d-7f6b0e95dc57"
      },
      "source": [
        "tweets_text_nltk.similar(\"Pimentel\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minas rt governador estado mg o que fora drogas e anos mas calamidade\n",
            "né resolver ensino gerais é com em\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB-8_1F_wPOr",
        "colab_type": "text"
      },
      "source": [
        "###**Conjunto de palavras empregadas similarmente**\n",
        "\n",
        "O método \".collocations()\" me permite saber quais palavras ou conjunto de palavras são mais usadas agrupadas. Isso dá ao desenvolvedor a possibilidade de aprender com o dado e ter vários insights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8iYytT3vHcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1ed75871-aca7-4216-ef39-7aaaff3f1cfa"
      },
      "source": [
        "tweets_text_nltk.collocations()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dois helicópteros; febre amarela; Minas Gerais; calamidade\n",
            "financeira,; compra mais; helicópteros!!A cara; @AnaPaulaVolei: Mais;\n",
            "estado. htt…; avisa Justiça; calamidade financeira; canalhice ainda;\n",
            "mais dois; são maiores; tem recursos; três anos,; Com três; conta\n",
            "judicial; anos, presídio; presídio privado; 21,8 milhões:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwWJKEJAwhuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtem a frequencia de cada palavra\n",
        "fdist = nltk.FreqDist(p.lower() for p in list_palavras)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWq0gIcdw0Ll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "2e4932ba-ab6c-4220-f8d4-b15ae6330b88"
      },
      "source": [
        "#EXIBINDO OS 20 TERMOS QUE MAIS APARECEM NA BASE DE DADOS E SUA RESPECTIVA FREQUÊNCIA\n",
        "\n",
        "fdist.most_common(20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 8624),\n",
              " ('em', 4478),\n",
              " ('rt', 3080),\n",
              " ('minas', 2945),\n",
              " ('e', 2269),\n",
              " ('estado', 2120),\n",
              " ('mg', 2004),\n",
              " ('-', 1937),\n",
              " ('a', 1889),\n",
              " ('governo', 1775),\n",
              " ('o', 1737),\n",
              " ('do', 1477),\n",
              " ('é', 1289),\n",
              " ('que', 1230),\n",
              " ('mais', 1157),\n",
              " ('gerais', 980),\n",
              " ('drogas', 917),\n",
              " ('com', 913),\n",
              " ('compra', 886),\n",
              " ('calamidade', 882)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE7bAhg7yhon",
        "colab_type": "text"
      },
      "source": [
        "###**Removendo StopWords**\n",
        "\n",
        "Na lista acima, reparamos que há vários tokens que não tem nenhuma relevância, como por exemplo \"de\", \"em\", \"e\", \"-\" etc.\n",
        "\n",
        "A melhor forma de remover essas palavras, é utilizando o método **\"StopWords\"**.\n",
        "\n",
        "StopWords são palavras reservadas do idioma usadas para uma boa articulação da ortografia, mas são palavras que quando estamos analisando um texto, mais prejudicam do que ajudam.\n",
        "\n",
        "A NLTK fornece um dicionário de \"stopwords\" para o idioma português."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uflx02Jw_et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a lista de StopWords\n",
        "\n",
        "stopwords = set(nltk.corpus.stopwords.words(\"portuguese\"))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJSgP5Ex0rXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d7aed9d-cfa8-4c1e-94ad-a792c0fcec30"
      },
      "source": [
        "stopwords"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estamos',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'não',\n",
              " 'nós',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'só',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tém',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'à',\n",
              " 'às',\n",
              " 'é',\n",
              " 'éramos'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HRsZT41Cwq",
        "colab_type": "text"
      },
      "source": [
        "###**Removendo as StopWords da lista de palavras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3cJKXmL0sXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cc149854-a874-4e60-c88f-9be3b10a7355"
      },
      "source": [
        "list_palavras = [i.lower() for i in list_palavras if not i.lower() in stopwords]\n",
        "\n",
        "print (list_palavras[:20])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['���⛪', '@', 'catedral', 'santo', 'antônio', '-', 'governador', 'valadares/mg', 'https://t.co/jsbkamiquj', '�', '@', 'governador', 'valadares,', 'minas', 'gerais', 'https://t.co/b3thidjcsf', '��', '@', 'governador', 'valadares,']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUPoqQWe1uGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b687de1-c4bb-4a6e-ade8-77fac0f57a7b"
      },
      "source": [
        "len(list_palavras)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwoea-Ji1xj4",
        "colab_type": "text"
      },
      "source": [
        "**Resultado**: muitas palavras da nossa lista de palavras, da nossa base de dados, foram removidas por serem classificadas como stopwords, ou seja, não tem relevância."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9hD9vJb1LPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtem a frequencia de cada palavra\n",
        "fdist = nltk.FreqDist(p.lower() for p in list_palavras)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6bonokV1NQJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "92f78d14-801c-42be-8586-8a00f20e12f8"
      },
      "source": [
        "fdist.most_common(20)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rt', 3080),\n",
              " ('minas', 2945),\n",
              " ('estado', 2120),\n",
              " ('mg', 2004),\n",
              " ('-', 1937),\n",
              " ('governo', 1775),\n",
              " ('gerais', 980),\n",
              " ('drogas', 917),\n",
              " ('compra', 886),\n",
              " ('calamidade', 882),\n",
              " ('dois', 879),\n",
              " ('helicópteros', 804),\n",
              " ('q', 672),\n",
              " ('governador', 651),\n",
              " ('presídio', 568),\n",
              " ('febre', 549),\n",
              " ('r$', 519),\n",
              " ('amarela', 506),\n",
              " ('pimentel', 465),\n",
              " ('ainda', 461)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFj1Yk8d2IVg",
        "colab_type": "text"
      },
      "source": [
        "Aqui já temos um resultado mais limpo, mais íntegro, com palavras que fazem muito mais sentido, tem muito mais relevância em relação ao que obtivemos anteriormente. Ou seja, termos os quais conseguimos explorar/trabalhar para identificar e gerar conhecimento para o nosso projeto.\n",
        "\n",
        "\n",
        "**CONTINUA...**"
      ]
    }
  ]
}